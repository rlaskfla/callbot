require("dotenv").config();
const express = require("express");
const fs = require("fs");
const path = require("path");
const { v4: uuidv4 } = require("uuid");
const bodyParser = require("body-parser");
const Twilio = require("twilio");
const { createServer } = require("http");
const { Server: IOServer } = require("socket.io");
const WebSocket = require("ws");
const sdk = require("microsoft-cognitiveservices-speech-sdk");
const fsp = require("fs").promises;
const { GoogleGenerativeAI } = require("@google/generative-ai");

const app = express();
const httpServer = createServer(app);
const io = new IOServer(httpServer);

app.use(bodyParser.urlencoded({ extended: false }));
app.use(bodyParser.json());
app.use(express.static(path.join(__dirname, "public")));

const {
  TWILIO_ACCOUNT_SID,
  TWILIO_AUTH_TOKEN,
  TWILIO_FROM_NUMBER,
  AZURE_SPEECH_KEY,
  AZURE_SPEECH_REGION,
  GEMINI_API_KEY,
  PORT = 3003,
  PUBLIC_HOST,
} = process.env;

if (
  !TWILIO_ACCOUNT_SID ||
  !TWILIO_AUTH_TOKEN ||
  !TWILIO_FROM_NUMBER ||
  !AZURE_SPEECH_KEY ||
  !AZURE_SPEECH_REGION ||
  !PUBLIC_HOST
) {
  console.warn(
    "‚ö†Ô∏è ÌôòÍ≤ΩÎ≥ÄÏàò ÎØ∏ÏÑ§Ï†ï: TWILIO_*, AZURE_SPEECH_*, PUBLIC_HOST ÌïÑÏöî."
  );
}

const twilioClient = Twilio(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN);
const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);

// ---------- Ïò§ÎîîÏò§ Ìè¥Îçî ----------
const AUDIO_DIR = path.join(__dirname, "audio");
if (!fs.existsSync(AUDIO_DIR)) fs.mkdirSync(AUDIO_DIR);
async function ensureDir(dir) {
  try {
    await fsp.mkdir(dir, { recursive: true });
  } catch {}
}

// ---------- Azure TTS ----------
async function synthesizeToFile(text, filename) {
  await ensureDir(AUDIO_DIR);
  const audioFile = path.join(AUDIO_DIR, filename);
  return new Promise((resolve, reject) => {
    const speechConfig = sdk.SpeechConfig.fromSubscription(
      AZURE_SPEECH_KEY,
      AZURE_SPEECH_REGION
    );
    speechConfig.speechSynthesisLanguage = "ko-KR";
    speechConfig.speechSynthesisVoiceName = "ko-KR-SunHiNeural";
    speechConfig.speechSynthesisOutputFormat =
      sdk.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw;
    const audioConfig = sdk.AudioConfig.fromAudioFileOutput(audioFile);
    const synthesizer = new sdk.SpeechSynthesizer(speechConfig, audioConfig);

    synthesizer.speakTextAsync(
      text || "",
      () => {
        synthesizer.close();
        console.log("[TTS ÏôÑÎ£å]", audioFile);
        resolve(audioFile);
      },
      (err) => {
        synthesizer.close();
        reject(err);
      }
    );
  });
}

// ---------- Twilio Ïû¨ÏÉù ----------
async function playToCall(callSid, audioUrl) {
  const base = PUBLIC_HOST;
  const wsBase = base.startsWith("https")
    ? base.replace(/^https/, "wss")
    : base.replace(/^http/, "ws");
  const wsUrl = `${wsBase}/media?callSid=${encodeURIComponent(callSid)}`;
  const twiml = [
    "<Response>",
    `<Start><Stream url=\"${wsUrl}\"/></Start>`,
    `<Play>${audioUrl}</Play>`,
    `<Pause length=\"1\"/>`,
    `<Redirect method=\"POST\">${base}/twilio/hold</Redirect>`,
    "</Response>",
  ].join("");
  console.log("üì® Twilio update callSid:", callSid);
  return twilioClient.calls(callSid).update({ twiml });
}

// ---------- Î∞úÏã† ----------
function generateCallScript(intentText) {
  return `ÏïàÎÖïÌïòÏÑ∏Ïöî. Í≥†Í∞ùÎãòÏùÑ ÎåÄÏã†Ìï¥ Í∞ÑÎã®Ìûà Î¨∏ÏùòÎìúÎ¶ΩÎãàÎã§. ${intentText}. Í∞ÄÎä•/Î∂àÍ∞ÄÎä•Îßå ÏïåÎ†§Ï£ºÏãúÎ©¥ Í∞êÏÇ¨ÌïòÍ≤†ÏäµÎãàÎã§.`;
}

app.post("/calls", async (req, res) => {
  try {
    const { phone, intentText } = req.body;
    if (!phone || !intentText)
      return res.status(400).json({ error: "phone and intentText required" });

    const script = generateCallScript(intentText);
    const filename = `${uuidv4()}.wav`;
    await synthesizeToFile(script, filename);
    const audioUrl = `${PUBLIC_HOST}/audio/${filename}`;

    const call = await twilioClient.calls.create({
      url: `${PUBLIC_HOST}/twilio/answer?audioUrl=${encodeURIComponent(
        audioUrl
      )}`,
      to: phone,
      from: TWILIO_FROM_NUMBER,
    });

    console.log("üìû Call initiated:", call.sid);
    res.json({ callSid: call.sid, script, audioUrl });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: err.message });
  }
});

// ---------- TwiML (Ìï≠ÏÉÅ callSidÎ•º Stream URLÏóê Ìè¨Ìï®) ----------
app.all("/twilio/answer", (req, res) => {
  const audioUrl = req.query.audioUrl;
  const callSid = req.body?.CallSid || req.query?.CallSid || "unknown";
  const wsBase = PUBLIC_HOST.startsWith("https")
    ? PUBLIC_HOST.replace(/^https/, "wss")
    : PUBLIC_HOST.replace(/^http/, "ws");
  const wsUrl = `${wsBase}/media?callSid=${encodeURIComponent(callSid)}`;

  const twiml = [
    '<?xml version="1.0" encoding="UTF-8"?>',
    "<Response>",
    `<Start><Stream url=\"${wsUrl}\"/></Start>`,
    `<Play>${audioUrl}</Play>`,
    '<Pause length="60"/>',
    `<Redirect method=\"POST\">${PUBLIC_HOST}/twilio/hold</Redirect>`,
    "</Response>",
  ];
  res.type("text/xml").send(twiml.join("\n"));
});

app.all("/twilio/hold", (req, res) => {
  const callSid = req.body?.CallSid || req.query?.CallSid || "unknown";
  const wsUrl = `${PUBLIC_HOST.replace(
    /^http/,
    "ws"
  )}/media?callSid=${encodeURIComponent(callSid)}`;
  const twiml = [
    '<?xml version="1.0" encoding="UTF-8"?>',
    "<Response>",
    `<Start><Stream url=\"${wsUrl}\"/></Start>`,
    '<Pause length="60"/>',
    `<Redirect method=\"POST\">${PUBLIC_HOST}/twilio/hold</Redirect>`,
    "</Response>",
  ];
  res.type("text/xml").send(twiml.join("\n"));
});

app.use("/audio", express.static(AUDIO_DIR));

// ---------- Œº-law ‚Üí PCM16 ----------
function mulawToPcm16(mulawBuffer) {
  const out = Buffer.alloc(mulawBuffer.length * 2);
  for (let i = 0; i < mulawBuffer.length; i++) {
    let mu = ~mulawBuffer[i] & 0xff;
    const sign = mu & 0x80 ? -1 : 1;
    const exponent = (mu >> 4) & 0x07;
    const mantissa = mu & 0x0f;
    let sample = ((mantissa << 3) + 0x84) << exponent;
    sample = sign * sample;
    out.writeInt16LE(sample, i * 2);
  }
  return out;
}

// ---------- STT + ÎåÄÌôîÍ∏∞ÏñµÌòï Gemini ----------
const wss = new WebSocket.Server({ noServer: true, perMessageDeflate: false });
const activeStreams = new Map();

httpServer.on("upgrade", (request, socket, head) => {
  if (request.url.startsWith("/media")) {
    wss.handleUpgrade(request, socket, head, (ws) => {
      wss.emit("connection", ws, request);
    });
  } else socket.destroy();
});

wss.on("connection", (ws, req) => {
  const params = new URLSearchParams(req.url.split("?")[1] || "");
  let callSid = params.get("callSid") || null;

  // ‚úÖ Twilio 'start' Ïù¥Î≤§Ìä∏Î°ú Î∞õÏùÄ callSidÎ°ú ÌôïÏ†ï
  function bindCallSid(newSid) {
    if (!newSid) return;
    if (callSid === newSid && activeStreams.get(newSid) === ws) return;

    if (activeStreams.has(newSid)) {
      try {
        activeStreams.get(newSid).close();
      } catch {}
      activeStreams.delete(newSid);
    }
    if (callSid && activeStreams.get(callSid) === ws) {
      activeStreams.delete(callSid);
    }
    callSid = newSid;
    activeStreams.set(callSid, ws);
    console.log("Twilio Media WS connected:", callSid);
  }

  if (callSid) bindCallSid(callSid);
  else console.log("Twilio Media WS connected: (awaiting start)");

  const speechConfig = sdk.SpeechConfig.fromSubscription(
    AZURE_SPEECH_KEY,
    AZURE_SPEECH_REGION
  );
  speechConfig.speechRecognitionLanguage = "ko-KR";
  const audioFormat = sdk.AudioStreamFormat.getWaveFormatPCM(8000, 16, 1);
  const pushStream = sdk.AudioInputStream.createPushStream(audioFormat);
  const audioConfig = sdk.AudioConfig.fromStreamInput(pushStream);
  const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);

  let lastRecognizedText = "";
  let lastRecognizedTime = 0;
  let conversationHistory = [];

  function isDuplicateRecognition(text) {
    const now = Date.now();
    const tooSoon = now - lastRecognizedTime < 2500;
    const isSame = text === lastRecognizedText;
    if ((isSame && tooSoon) || (text.length <= 3 && tooSoon)) return true;
    lastRecognizedText = text;
    lastRecognizedTime = now;
    return false;
  }

  // ‚úÖ ÏµúÏ¢Ö Ïù∏ÏãùÎßå Ï≤òÎ¶¨ (Ï§ëÍ∞Ñ Ïù∏Ïãù Î¨¥Ïãú)
  recognizer.recognized = async (s, e) => {
    if (
      !e.result ||
      e.result.reason !== sdk.ResultReason.RecognizedSpeech ||
      !e.result.text.trim()
    )
      return;

    const text = e.result.text.trim();
    if (isDuplicateRecognition(text)) return;

    console.log("[üéß ÏµúÏ¢Ö Ïù∏Ïãù Í≤∞Í≥º]", text);
    conversationHistory.push({ role: "user", content: text });
    if (conversationHistory.length > 20)
      conversationHistory = conversationHistory.slice(-20);

    io.emit("stt.final", { text, callSid });

    try {
      const model = genAI.getGenerativeModel({
        model: "models/gemini-2.0-flash",
      });

      const historyText = conversationHistory
        .map((m) => `${m.role === "user" ? "ÏÇ¨Ïö©Ïûê" : "AI"}: ${m.content}`)
        .join("\n");

      const prompt = `
ÎÑàÎäî ÏßÄÍ∏à Ï†ÑÌôîÎ•º Í±¥ "ÏÜêÎãò"Ïùò Ïó≠Ìï†ÏûÖÎãàÎã§.
ÎÑàÎäî Í∞ÄÍ≤å, ÏãùÎãπ, Î≥ëÏõê, Ï†ÑÏãúÌöå Îì±ÏóêÏÑú ÏòàÏïΩ ÎòêÎäî Î¨∏ÏùòÎ•º ÌïòÍ≥† ÏûàÏäµÎãàÎã§.

### Ï†àÎåÄ ÏßÄÏºúÏïº ÌïòÎäî Í∑úÏπô
1) ÎÑàÎäî **ÏÜêÎãò**Ïù¥Í≥† ÏÉÅÎåÄÎ∞©ÏùÄ **ÏßÅÏõê**ÏûÖÎãàÎã§. Ï†àÎåÄ ÏßÅÏõêÏ≤òÎüº ÎßêÌïòÏßÄ ÏïäÏäµÎãàÎã§.
2) ÏÉÅÎåÄÎ∞©Ïù¥ Ïù¥ÎØ∏ Ï†ïÎ≥¥Î•º Ï§¨Îã§Î©¥ **Ï∂îÍ∞ÄÎ°ú ÎêòÎ¨ªÏßÄ ÏïäÏäµÎãàÎã§.**
3) ÏÉÅÎåÄÎ∞©Ïù¥ "ÏòàÏïΩÌï¥ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§ / Ï≤òÎ¶¨ÌïòÍ≤†ÏäµÎãàÎã§ / ÏïåÍ≤†ÏäµÎãàÎã§ / ÌôïÏù∏ÌñàÏäµÎãàÎã§" Îì±
   **ÎåÄÌôîÎ•º Ï¢ÖÎ£åÌïòÎäî ÌëúÌòÑÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥, Î∞îÎ°ú**  
   ‚Üí "ÎÑ§, Í∞êÏÇ¨Ìï©ÎãàÎã§." **Ìïú Î¨∏Ïû•ÏúºÎ°ú ÎÅùÎÉÖÎãàÎã§.**
4) Î∂àÌïÑÏöîÌïú ÏßàÎ¨∏, ÌôïÏû• ÏßàÎ¨∏, ÏÉàÎ°úÏö¥ Ï†úÏïà Í∏àÏßÄ.
5) ÎãµÎ≥ÄÏùÄ Ìï≠ÏÉÅ **ÏßßÍ≥† Î™ÖÌôïÌïòÍ≤å**, Ìïú Î¨∏Ïû•.
6) Î¨∏Ïû•ÏùÄ **Ï†ïÏ§ëÌïú ÏöîÏ≤≠ ÎòêÎäî Í∞ÑÎã®Ìïú ÎãµÎ≥Ä ÌòïÌÉú**Î°ú ÎÅùÎÇ©ÎãàÎã§.
7) **Í≥ºÍ±∞ ÎåÄÌôîÎ•º Î™®Îëê Í∏∞ÏñµÌïòÎäî Í≤ÉÏ≤òÎüº ÏùºÍ¥ÄÎêòÍ≤å ÏùëÎãµ**Ìï©ÎãàÎã§. (Ïù¥ÎØ∏ ÎßêÌïú ÎÇ¥Ïö©ÏùÑ Î∞òÎ≥µÌïòÏßÄ ÏïäÏùå)

### ÏòàÏãú
- "Ïò§Îäò 7Ïãú Îëê Î™Ö ÏòàÏïΩ Í∞ÄÎä•Ìï†ÍπåÏöî?"
- "ÎÑ§, Îëê Î™Ö Î™®Îëê ÏÑ±Ïù∏ÏûÖÎãàÎã§."
- "Í∑∏Îü¨Î©¥ 6ÏãúÎ°ú Î∂ÄÌÉÅÎìúÎ¶¨Í≤†ÏäµÎãàÎã§."
- "ÎÑ§, Í∞êÏÇ¨Ìï©ÎãàÎã§."

### ÏûÖÎ†•
ÏßÄÍ∏àÍπåÏßÄÏùò ÎåÄÌôî Í∏∞Î°ù: ${historyText}
ÏÉÅÎåÄÎ∞©Ïù¥ Î∞©Í∏à ÎßêÌïú ÎÇ¥Ïö©: "${text}"

### Ï∂úÎ†• ÌòïÏãù
- ÏÜêÎãòÏùò Îã§Ïùå Î∞úÌôî 1Î¨∏Ïû•Îßå Ï∂úÎ†•
- Ï∂îÍ∞Ä ÏÑ§Î™Ö, Í¥ÑÌò∏, Îî∞Ïò¥Ìëú, Ìï¥ÏÑ§ Í∏àÏßÄ


      `;

      const result = await model.generateContent(prompt);
      let replyText = result.response.text().trim();
      replyText = replyText
        .replace(/```json/gi, "")
        .replace(/```/g, "")
        .trim();

      let replies = [];
      try {
        const parsed = JSON.parse(replyText);
        if (Array.isArray(parsed))
          replies = parsed.map((v) => v.toString().trim());
      } catch {
        replies = replyText
          .split(/[\n,]/)
          .map((v) => v.trim().replace(/^"+|"+$/g, ""))
          .filter(Boolean);
      }

      replies = [...new Set(replies)].slice(0, 3);
      io.emit("recommendations", { callSid, replies });
      conversationHistory.push({
        role: "assistant",
        content: replies.join(" / "),
      });
    } catch (err) {
      console.error("[Gemini Ïò§Î•ò]", err);
    }
  };

  ws.on("message", (msg) => {
    try {
      const data = JSON.parse(msg.toString());
      if (data.event === "start") {
        const sid = data.start?.callSid || data.callSid;
        if (sid) bindCallSid(sid);
        console.log("üéß Media stream started:", callSid || sid || "(unknown)");
      } else if (data.event === "media" && data.media?.payload) {
        const mulaw = Buffer.from(data.media.payload, "base64");
        const pcm16 = mulawToPcm16(mulaw);
        pushStream.write(pcm16);
      } else if (data.event === "stop") {
        console.log("üõë Media stream stopped:", callSid || "(unknown)");
        pushStream.close();
        recognizer.stopContinuousRecognitionAsync(() => recognizer.close());
      }
    } catch (e) {
      console.error("WS parse error:", e);
    }
  });

  ws.on("close", () => {
    console.log("üîö Twilio WS closed:", callSid || "(unknown)");
    if (callSid && activeStreams.get(callSid) === ws) {
      activeStreams.delete(callSid);
    }
    pushStream.close();
    recognizer.stopContinuousRecognitionAsync(() => recognizer.close());
  });

  recognizer.startContinuousRecognitionAsync(
    () => console.log("[STT] Recognition started:", callSid || "(pending)"),
    (err) => console.error("[STT] start error", err)
  );
});

// ---------- ÌîÑÎ°†Ìä∏ ÏÜåÏºì ----------
io.on("connection", (socket) => {
  console.log("Frontend socket.io connected");

  socket.on("bind.call", ({ callSid }) => {
    console.log("üîó callSid Ïó∞Í≤∞Îê®:", callSid);
    socket.data.callSid = callSid;
  });

  socket.on("replySelected", async ({ text, callSid }) => {
    try {
      const filename = `${uuidv4()}.wav`;
      await synthesizeToFile(text, filename);
      const audioUrl = `${PUBLIC_HOST}/audio/${filename}`;
      await playToCall(callSid, audioUrl);
      console.log("üîä Î≤ÑÌäº TTS Ïû¨ÏÉù:", text);
    } catch (err) {
      console.error("Î≤ÑÌäº Ïû¨ÏÉù Ïò§Î•ò:", err);
    }
  });

  socket.on("say", async ({ text }) => {
    try {
      const sockets = await io.fetchSockets();
      const active = sockets.find((s) => s.data?.callSid);
      const callSid = active ? active.data.callSid : null;
      if (!callSid) {
        socket.emit("say.error", { message: "ÌÜµÌôî Ï§ëÏù¥ ÏïÑÎãôÎãàÎã§." });
        return;
      }
      const filename = `${uuidv4()}.wav`;
      await synthesizeToFile(text, filename);
      const audioUrl = `${PUBLIC_HOST}/audio/${filename}`;
      await playToCall(callSid, audioUrl);
      socket.emit("say.result", { ok: true });
      console.log("üîä [say Ïû¨ÏÉù ÏÑ±Í≥µ]:", text);
    } catch (err) {
      socket.emit("say.error", { message: err.message });
    }
  });
});

app.get("/health", (req, res) => res.json({ ok: true }));

httpServer.listen(PORT, () => {
  console.log(`‚úÖ Server running on port ${PORT}`);
  console.log(`PUBLIC_HOST=${PUBLIC_HOST}`);
});
